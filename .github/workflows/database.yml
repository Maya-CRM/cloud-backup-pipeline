---
name: Backup Application Database

on:
  workflow_call:
    inputs:
      DATABASE_BACKUP_RETAIN:
        type: string
        required: true
      FILE_BACKUP_RETAIN:
        type: string
        required: true
      AWS_REGION:
        type: string
        required: true
      AWS_S3_BUCKET:
        type: string
        required: true
      AWS_S3_OBJECT:
        type: string
        required: true
      AWS_S3_ENDPOINT:
        type: string
        required: true
      SERVER_PORT:
        type: string
        required: true
      SERVER_HOSTNAME:
        type: string
        required: true
      SERVER_USERNAME:
        type: string
        required: true
      MYSQL_HOST:
        type: string
        required: true
      MYSQL_PORT:
        type: string
        required: true
      MYSQL_USER:
        type: string
        required: true
      MYSQL_DATABASE:
        type: string
        required: true
      FILE_BACKUP_APPLICATION_PATH:
        type: string
        required: true

jobs:
  backup:
    name: Backup Database
    runs-on: ubuntu-22.04
    container: python:3.8
    steps:
      - name: Set runtime variables
        id: vars
        run: |
          echo "timestamp=$(date -d@"$(( \
          $(date +%s) + (5 * 3600) + (30 * 60) ))" \
          +'%d-%m-%Y-%H%M')" >> "$GITHUB_ENV"

      - name: Install system packages
        run: |
          apt-get update --assume-yes
          apt-get install rsync --assume-yes

      - name: Install AWS CLI
        run: |
          pip install awscli

      - name: Manually Set SSH key
        if: ${{ env.ACT }}
        run: |
          mkdir --parents ~/.ssh
          touch ~/.ssh/id_rsa
          echo "${{ secrets.SERVER_SECRET_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: Load SSH key
        uses: webfactory/ssh-agent@v0.8.0
        if: ${{ !env.ACT }}
        with:
          ssh-private-key: ${{ secrets.SERVER_SECRET_KEY }}

      - name: Dump MySQL database
        uses: appleboy/ssh-action@v0.1.10
        env:
          TIMESTAMP: ${{ env.timestamp }}
        with:
          host: ${{ inputs.SERVER_HOSTNAME }}
          username: ${{ inputs.SERVER_USERNAME }}
          key: ${{ secrets.SERVER_SECRET_KEY }}
          port: ${{ inputs.SERVER_PORT }}
          envs: TIMESTAMP
          script: |
            mkdir --parent /srv/rsync/backups

            mysqldump \
            --quick \
            --single-transaction \
            --host=${{ inputs.MYSQL_HOST }} \
            --port=${{ inputs.MYSQL_PORT }} \
            --user=${{ inputs.MYSQL_USER }} \
            --password=${{ secrets.MYSQL_PASS }} \
            --databases ${{ inputs.MYSQL_DATABASE }} > /srv/rsync/backups/$TIMESTAMP-mysql.sql

            cd /srv/rsync/backups && gzip $TIMESTAMP-mysql.sql

      - name: Transport database
        env:
          TIMESTAMP: ${{ env.timestamp }}
        run: |
          mkdir --parents /srv/rsync/backups 

          rsync \
          --delete \
          --verbose \
          --archive \
          --checksum \
          --compress \
          --remove-source-files \
          --rsh "ssh -o StrictHostKeyChecking=no" \
          ${{ inputs.SERVER_USERNAME }}@${{ inputs.SERVER_HOSTNAME }}:/srv/rsync/backups/$TIMESTAMP-mysql.sql.gz \
          /srv/rsync/backups/${{ env.timestamp }}-mysql.sql.gz

      - name: Configure AWS credentials
        run: |
          mkdir --parents ~/.aws
          echo "[default]" > ~/.aws/credentials
          echo "aws_access_key_id = ${{ secrets.AWS_ACCESS_KEY_ID }}" >> ~/.aws/credentials
          echo "aws_secret_access_key = ${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> ~/.aws/credentials
          echo "[default]" > ~/.aws/config
          echo "region = ${{ secrets.AWS_REGION }}" >> ~/.aws/config

      - name: Upload backup to S3 bucket
        run: >
          aws s3 cp 
          /srv/rsync/backups/${{ env.timestamp }}-mysql.sql.gz
          s3://${{ inputs.AWS_S3_BUCKET }}/${{ inputs.AWS_S3_OBJECT }}/${{ env.timestamp }}-mysql.sql.gz 
          --endpoint-url ${{ inputs.AWS_S3_ENDPOINT }}

      - name: List backups in S3 bucket
        id: list-backups
        run: >
          BACKUPS=$(aws s3 ls s3://${{ inputs.AWS_S3_BUCKET }}/${{ inputs.AWS_S3_OBJECT }} \
            --recursive \
            --endpoint-url ${{ inputs.AWS_S3_ENDPOINT }} \
            | awk '{$1=$2=$3=""; print $0}' \
            | sed 's/^[ \t]*//' \
          )
          echo "::set-output name=backups::${BACKUPS}"

      - name: Delete excess backups in S3 bucket
        run: >
          counter=0

          files=$(aws s3api list-objects \
            --bucket "${{ inputs.AWS_S3_BUCKET }}" \
            --prefix "${{ inputs.AWS_S3_OBJECT }}/" \
            --query 'Contents[?ends_with(Key, `'-mysql.sql.gz'`)].[Key, LastModified]' \
            --output text \
            --endpoint-url ${{ inputs.AWS_S3_ENDPOINT }} \
            | sort -k2 -r \
            | awk '{print $1}' \
          )

          for file in $files; do
              counter=$((counter + 1))
              if [ $counter -le ${{ inputs.DATABASE_BACKUP_RETAIN }} ]; then
                continue
              fi
              aws s3 rm s3://${{ inputs.AWS_S3_BUCKET }}/$file --endpoint-url ${{ inputs.AWS_S3_ENDPOINT }};
          done

      - name: Discord success notification
        uses: Ilshidur/action-discord@master
        if: success()
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        with:
          args: "ðŸŸ¢ Database backup completed at: ${{ env.timestamp }}."

      - name: Discord failure notification
        uses: Ilshidur/action-discord@master
        if: failure()
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        with:
          args: "ðŸ›‘ Database backup failed at: ${{ env.timestamp }}."
